"""train.py

NeurLZ é£æ ¼çš„é«˜æ€§èƒ½åœ¨çº¿è®­ç»ƒå¾ªç¯ (Cross-Field + High-Frequency PE ä¼˜åŒ–ç‰ˆ)
"""

from __future__ import annotations
from dataclasses import dataclass
from typing import List, Dict, Any
import numpy as np
import torch
import torch.nn.functional as F
import copy
import math

from Patch_data import sample_bg_patches_multifield, sample_roi_slabs_multifield
from siren_fft_backbone_model import Cascaded_BG_ROI_Model

# 1. ç¼“å­˜ DCT å˜æ¢çŸ©é˜µ (é¿å…é‡å¤è®¡ç®—)
_dct_matrix_cache = {}

def get_dct_matrix(N, device):
    """ç”Ÿæˆ N x N çš„ 1D DCT-II æ­£äº¤å˜æ¢çŸ©é˜µ"""
    if (N, device) in _dct_matrix_cache:
        return _dct_matrix_cache[(N, device)]
    
    n = torch.arange(N, device=device).float()
    k = torch.arange(N, device=device).float().unsqueeze(1)
    C = torch.cos(math.pi * k * (2 * n + 1) / (2 * N))
    C[0, :] /= math.sqrt(2)
    C *= math.sqrt(2 / N)
    
    # å°†å½¢çŠ¶è°ƒæ•´ä¸º (1, 1, N, N) ä»¥ä¾¿ç›´æ¥ä¸ (B, C, H, W) è¿›è¡Œå¹¿æ’­çŸ©é˜µä¹˜æ³•
    _dct_matrix_cache[(N, device)] = C.unsqueeze(0).unsqueeze(0)
    return _dct_matrix_cache[(N, device)]

def dct_2d(x):
    """é«˜æ•ˆ 2D DCT å˜æ¢ (åŸºäºå¼ é‡çŸ©é˜µä¹˜æ³•)"""
    H, W = x.shape[-2:]
    C_h = get_dct_matrix(H, x.device)           # (1, 1, H, H)
    C_w_t = get_dct_matrix(W, x.device).transpose(-1, -2) # (1, 1, W, W)
    
    # 2D DCT å…¬å¼: Y = C_h @ X @ C_w^T
    out = torch.matmul(C_h, x)      # æ²¿é«˜åº¦å˜æ¢
    out = torch.matmul(out, C_w_t)  # æ²¿å®½åº¦å˜æ¢
    return out

# 2. å®šä¹‰çº¯æ­£çš„ DCT é¢‘åŸŸæŸå¤±
def dct_frequency_loss(pred, target):
    pred_dct = dct_2d(pred)
    target_dct = dct_2d(target)
    # å› ä¸º DCT æ˜¯å®æ•°ï¼Œç›´æ¥ç®— L1 ç»å¯¹è¯¯å·®ï¼å®Œç¾ä¿ç•™ç»“æ„ç‰¹å¾
    return F.l1_loss(pred_dct, target_dct)

# 1. åœ¨ TrainConfig ä¸­åŠ å…¥ input å±æ€§
@dataclass
class TrainConfig:
    epochs: int = 1
    steps_per_epoch: int = 50
    bg_batch: int = 256
    roi_batch: int = 256
    bg_patch: int = 64
    roi_patch: int = 32
    lr: float = 1e-4
    min_lr: float = 1e-5
    weight_decay: float = 1e-4
    grad_clip: float = 0.5
    alpha_roi: float = 0.1
    abs_err: float = 1e-3
    use_amp: bool = False
    
    # æ ¸å¿ƒæ–°å¢ï¼šè®°å½•è¾“å…¥åœºå’Œæ®‹å·®çš„å…¨å±€ç»Ÿè®¡é‡
    res_mean: float = 0.0
    res_std: float = 1.0
    input_means: list = None
    input_stds: list = None

# 2. ä¿®æ”¹ training_step_multifield
def training_step_multifield(
    model, optimizer, Xs, Xps, roi_list_zyx, device, cfg
):
    model.train()
    optimizer.zero_grad(set_to_none=True)
    loss = 0.0; L_bg = 0.0; L_roi = 0.0
    n_fields = len(Xs)
    
    # æ„å»ºè¾“å…¥ç‰¹å¾çš„å¼ é‡åŒ–å…¨å±€å‚æ•°
    mean_t = torch.tensor(cfg.input_means, device=device).view(1, n_fields, 1, 1)
    std_t = torch.tensor(cfg.input_stds, device=device).view(1, n_fields, 1, 1)

    # ==========================================
    # 1. BG åˆ†æ”¯
    # ==========================================
    bg = sample_bg_patches_multifield(Xs, Xps, n=cfg.bg_batch, patch=cfg.bg_patch)
    if bg["xp"].shape[0] > 0:
        xp_bg = torch.from_numpy(bg["xp"]).to(device)
        x_target = torch.from_numpy(bg["x"]).to(device)
        z, y0, x0 = torch.from_numpy(bg["z"]).to(device), torch.from_numpy(bg["y0"]).to(device), torch.from_numpy(bg["x0"]).to(device)
        
        # ã€è¾“å…¥ X' å…¨å±€æ ‡å‡†åŒ–ã€‘
        xp_bg_norm = (xp_bg - mean_t) / std_t
        
        # ã€è¾“å‡ºæ®‹å·® R å…¨å±€æ ‡å‡†åŒ–ã€‘
        raw_res_bg = x_target - xp_bg[:, 0:1, :, :] 
        target_res_bg_norm = (raw_res_bg - cfg.res_mean) / cfg.res_std
        
        r_hat_bg_norm = model.bg_forward(xp_bg_norm, z, y0, x0)
        
        L_bg = F.mse_loss(r_hat_bg_norm, target_res_bg_norm)
        loss = loss + L_bg

    # ==========================================
    # 2. ROI åˆ†æ”¯
    # ==========================================
    if cfg.alpha_roi > 0 and roi_list_zyx.shape[0] > 0:
        roi = sample_roi_slabs_multifield(Xs, Xps, roi_list_zyx, n=cfg.roi_batch, K=model.K, patch=cfg.roi_patch)
        if roi["xp"].shape[0] > 0:
            xp_roi = torch.from_numpy(roi["xp"]).to(device)
            x_target_roi = torch.from_numpy(roi["x"]).to(device)
            z0, y0, x0 = torch.from_numpy(roi["z0"]).to(device), torch.from_numpy(roi["y0"]).to(device), torch.from_numpy(roi["x0"]).to(device)

            # ã€è¾“å…¥ Slab å…¨å±€æ ‡å‡†åŒ–ã€‘éœ€è¦æŠŠ mean å’Œ std æ²¿æ·±åº¦æ–¹å‘å¤åˆ¶ K æ¬¡
            mean_t_roi = mean_t.repeat_interleave(model.K, dim=1)
            std_t_roi = std_t.repeat_interleave(model.K, dim=1)
            xp_roi_norm = (xp_roi - mean_t_roi) / std_t_roi

            with torch.no_grad():
                N_roi, _, P, P_ = xp_roi.shape
                xp_roi_2d_norm = xp_roi_norm.view(N_roi * model.K, n_fields, P, P_)
                
                z_offsets = torch.arange(model.K, device=device).unsqueeze(0).expand(N_roi, -1)
                z_all = (z0.unsqueeze(1) + z_offsets).reshape(-1)
                y0_all = y0.unsqueeze(1).expand(-1, model.K).reshape(-1)
                x0_all = x0.unsqueeze(1).expand(-1, model.K).reshape(-1)

                r_bg_base_norm = model.bg_forward(xp_roi_2d_norm, z_all, y0_all, x0_all)
                r_bg_base_norm = r_bg_base_norm.view(N_roi, model.K, P, P_) 

            r_hat_delta_norm = model.roi_forward_delta(xp_roi_norm, z0, y0, x0)

            # ã€è¾“å‡ºæ®‹å·® R å…¨å±€æ ‡å‡†åŒ–ã€‘
            raw_res_roi = x_target_roi - xp_roi[:, 0:model.K, :, :]
            target_res_roi_norm = (raw_res_roi - cfg.res_mean) / cfg.res_std
            
            L_roi = F.mse_loss(r_bg_base_norm + r_hat_delta_norm, target_res_roi_norm)
            loss = loss + cfg.alpha_roi * L_roi

    if isinstance(loss, torch.Tensor):
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)
        optimizer.step()
        return {"loss": loss.item(), "L_bg": float(L_bg), "L_roi": float(L_roi), "skipped": False}
    else:
        return {"loss": 0.0, "L_bg": 0.0, "L_roi": 0.0, "skipped": True}

# train.py (æ ¸å¿ƒä¿®å¤ç‰ˆ)

def train_online_multifield(Xs, Xps, roi_list_zyx, device, cfg, evaluator=None, verbose=True):
    from siren_fft_backbone_model import Cascaded_BG_ROI_Model
    n_fields = len(Xs)
    model = Cascaded_BG_ROI_Model(n_fields=n_fields, K=7).to(device)
    
    # è°ƒæ•´å­¦ä¹ ç‡å’Œæƒé‡è¡°å‡
    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg.epochs, eta_min=cfg.min_lr)

    # æ ¸å¿ƒä¿®æ­£ 2ï¼šæé€Ÿé¢„ç¼“å­˜ ROI (æ¶ˆé™¤é‡‡æ ·å»¶è¿Ÿ)
    if verbose: print(f"--- é¢„ç¼“å­˜ {len(roi_list_zyx)} ä¸ª ROI Slabs ---")
    roi_data = sample_roi_slabs_multifield(Xs, Xps, roi_list_zyx, n=len(roi_list_zyx), K=7, patch=32)
    roi_xp_cache = torch.from_numpy(roi_data["xp"]).to(device)
    roi_target_cache = torch.from_numpy(roi_data["x"]).to(device)
    roi_z0, roi_y0, roi_x0 = [torch.from_numpy(roi_data[k]).to(device) for k in ["z0", "y0", "x0"]]

    history = {"epoch": [], "loss": [], "psnr": []}
    mean_t = torch.tensor(cfg.input_means, device=device).view(1, n_fields, 1, 1)
    std_t = torch.tensor(cfg.input_stds, device=device).view(1, n_fields, 1, 1)

    mse_base = float(np.mean((Xs[0] - Xps[0])**2))
    rng_base = float(np.max(Xs[0]) - np.min(Xs[0]))
    base_psnr = 20.0 * np.log10(rng_base / np.sqrt(mse_base)) if mse_base > 0 else 999.0

    history["psnr"].append((0, base_psnr)) # è®°å½•åˆ°ç”»å›¾æ•°æ®ä¸­
    best_psnr = base_psnr                  # å°† base psnr è®¾ä¸ºä¿åº•åˆ†æ•°
    best_model_weights = None
    if verbose:
        print(f"  [Init] Epoch   0 | Base SZ3 PSNR: {base_psnr:.2f} dB")
    for ep in range(cfg.epochs):
        model.train()
        epoch_losses = []
        use_freq_loss =  (ep >5)
        for _ in range(cfg.steps_per_epoch):
            optimizer.zero_grad(set_to_none=True)
            
            # 1. BG åˆ†æ”¯ (ä½¿ç”¨ 256x256 é‡‡æ ·)
            bg = sample_bg_patches_multifield(Xs, Xps, n=cfg.bg_batch, patch=cfg.bg_patch)
            xp_bg_norm = (torch.from_numpy(bg["xp"]).to(device) - mean_t) / std_t
            # ç›®æ ‡æ˜¯å¯¹é½åçš„ç‰©ç†æ®‹å·®
            target_bg = (torch.from_numpy(bg["x"]).to(device) - torch.from_numpy(bg["xp"][:,0:1]).to(device)) / cfg.res_std
            
            pred_bg = model.bg_forward(xp_bg_norm, torch.from_numpy(bg["z"]).to(device), 
                                       torch.from_numpy(bg["y0"]).to(device), torch.from_numpy(bg["x0"]).to(device))
            # ã€æ··åˆ Lossï¼šç©ºé—´ MSE + é¢‘åŸŸ DCT L1ã€‘
            l_bg_spatial = F.mse_loss(pred_bg, target_bg)
            if use_freq_loss:
                l_bg_freq = dct_frequency_loss(pred_bg, target_bg)
                l_bg = l_bg_spatial + 0.0001 * l_bg_freq
            else:
                l_bg = l_bg_spatial

            # 2. ROI åˆ†æ”¯ (çº§è”è®­ç»ƒ)
            idx = torch.randperm(roi_xp_cache.size(0))[:cfg.roi_batch]
            xp_roi_norm = (roi_xp_cache[idx] - mean_t.repeat_interleave(7, dim=1)) / std_t.repeat_interleave(7, dim=1)
            
            with torch.no_grad():
                N_b = xp_roi_norm.size(0)
                # è®¡ç®— BG çš„çº§è”è´¡çŒ®
                r_base = model.bg_forward(xp_roi_norm.view(N_b*7, n_fields, 32, 32), 
                                          roi_z0[idx].repeat_interleave(7), 
                                          roi_y0[idx].repeat_interleave(7), 
                                          roi_x0[idx].repeat_interleave(7)).view(N_b, 7, 32, 32)
            
            delta_roi = model.roi_forward_delta(xp_roi_norm, roi_z0[idx], roi_y0[idx], roi_x0[idx])
            target_roi = (roi_target_cache[idx] - roi_xp_cache[idx, 0:7]) / cfg.res_std
            pred_roi = r_base + delta_roi
            l_roi_spatial = F.mse_loss(pred_roi, target_roi)
            if use_freq_loss:
                l_roi_freq = dct_frequency_loss(pred_roi, target_roi)
                l_roi = l_roi_spatial + 0.0001 * l_roi_freq
            else:
                l_roi = l_roi_spatial
            loss = l_bg + cfg.alpha_roi * l_roi
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)
            optimizer.step()
            epoch_losses.append(loss.item())

        scheduler.step()
        # æ§åˆ¶è¯„ä¼°é¢‘ç‡ï¼šæ¯ 5 è½®è¯„ä¼°ä¸€æ¬¡
        if evaluator:
            cur_p = evaluator(model)
            history["psnr"].append((ep+1, cur_p))
            if verbose: 
                print(f"  Epoch {ep+1:3d} | Loss: {np.mean(epoch_losses):.6f} | PSNR: {cur_p:.2f} dB", end="")

            # ã€æ ¸å¿ƒæ–°å¢ 2ã€‘ï¼šå¦‚æœåˆ›ä¸‹æ–°çºªå½•ï¼Œä¿å­˜å½“å‰çµé­‚ (æƒé‡)
            if cur_p > best_psnr:
                best_psnr = cur_p
                # å› ä¸ºæ¨¡å‹æå°(36KB)ï¼Œdeepcopy æ¯«æ— æ€§èƒ½å‹åŠ›
                best_model_weights = copy.deepcopy(model.state_dict())
                if verbose: print("  ğŸŒŸ [New Best!]")
            else:
                if verbose: print()

    # ã€æ ¸å¿ƒæ–°å¢ 3ã€‘ï¼šè®­ç»ƒç»“æŸï¼Œå¼ºåˆ¶å›æ»šåˆ°æœ€å·…å³°æ—¶åˆ»ï¼
    if best_model_weights is not None:
        model.load_state_dict(best_model_weights)
        if verbose: 
            print(f"\n--- è®­ç»ƒç»“æŸï¼Œæ¨¡å‹å·²è‡ªåŠ¨å›æ»šè‡³å·…å³°çŠ¶æ€ (PSNR: {best_psnr:.2f} dB) ---")

    return model, history